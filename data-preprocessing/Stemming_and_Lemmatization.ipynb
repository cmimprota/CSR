{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "import string\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"twitter-datasets/train_pos.txt\")\n",
    "tweets = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Replace Abbreviations + Spell Correction using Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/nerd-stuff/python-script-to-turn-text-message-abbreviations-into-actual-phrases-d5db6f489222\n",
    "\n",
    "def translator(user_string):\n",
    "    user_string = user_string.split(\" \")\n",
    "    j = 0\n",
    "    for _str in user_string:\n",
    "        # File path which consists of Abbreviations.\n",
    "        fileName = \"./slang.txt\"\n",
    "        # File Access mode [Read Mode]\n",
    "        accessMode = \"r\"\n",
    "        with open(fileName, accessMode) as myCSVfile:\n",
    "            # Reading file as CSV with delimiter as \"=\", so that abbreviation are stored in row[0] and phrases in row[1]\n",
    "            dataFromFile = csv.reader(myCSVfile, delimiter=\"=\")\n",
    "            # Removing Special Characters.\n",
    "            _str = re.sub('[^a-zA-Z0-9-_.]', '', _str)\n",
    "            for row in dataFromFile:\n",
    "                # Check if selected word matches short forms[LHS] in text file.\n",
    "                if _str.upper() == row[0]:\n",
    "                    # If match found replace it with its appropriate phrase in text file.\n",
    "                    user_string[j] = row[1]\n",
    "            myCSVfile.close()\n",
    "        j = j + 1\n",
    "    # Replacing commas with spaces for final output.\n",
    "    print(' '.join(user_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "because your logic is so dumb , i won't even crop out your name or your photo . tsk . <url>\n",
      "\n",
      "because your logic is so dumb , i won't even crop out your name or your photo . tsk . <url>\n",
      "\n",
      "----------------------------\n",
      "\" <user> just put casper in a box ! \" looved the battle ! #crakkbitch\n",
      "\n",
      "\" <user> just put casper in a box ! \" looved the battle ! #crakkbitch\n",
      "\n",
      "----------------------------\n",
      "<user> <user> thanks sir > > don't trip lil mama ... just keep doin ya thang !\n",
      "\n",
      "<user> <user> thanks sir > > don't trip lil mama ... just keep doin ya thang !\n",
      "\n",
      "----------------------------\n",
      "visiting my brother tmr is the bestest birthday gift eveerrr ! ! !\n",
      "\n",
      "visiting my brother tmr is the bestest birthday gift eveerrr ! ! !\n",
      "\n",
      "----------------------------\n",
      "<user> yay ! ! #lifecompleted . tweet / facebook me to let me know please\n",
      "\n",
      "<user> yay ! ! #lifecompleted . tweet / facebook me to let me know please\n",
      "\n",
      "----------------------------\n",
      "<user> #1dnextalbumtitle : feel for you / rollercoaster of life . song cocept : life , #yolo , becoming famous ? <3 14 #followmeplz ! <3 x15\n",
      "\n",
      "<user> #1dnextalbumtitle : feel for you / rollercoaster of life . song cocept : life , #yolo , becoming famous ? <3 14 #followmeplz ! <3 x15\n",
      "\n",
      "----------------------------\n",
      "workin hard or hardly workin rt <user> at hardee's with my future coworker <user>\n",
      "\n",
      "workin hard or hardly workin rt <user> at hardee's with my future coworker <user>\n",
      "\n",
      "----------------------------\n",
      "<user> i saw . i'll be replying in a bit .\n",
      "\n",
      "<user> i saw . i'll be replying in a bit .\n",
      "\n",
      "----------------------------\n",
      "this is were i belong\n",
      "\n",
      "this is were i belong\n",
      "\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "for _tweet in tweets[1:10]:\n",
    "    print(_tweet)\n",
    "    translator(_tweet)\n",
    "    print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "because your logic is so dumb , i won't even crop out your name or your photo . tsk . <url>\n",
      "\n",
      "['because', 'your', 'logic', 'is', 'so', 'dumb', '', 'i', 'wont', 'even', 'crop', 'out', 'your', 'name', 'or', 'your', 'photo', '', 'tsk', '', 'url']\n",
      "\" <user> just put casper in a box ! \" looved the battle ! #crakkbitch\n",
      "\n",
      "['', 'user', 'just', 'put', 'casper', 'in', 'a', 'box', '', '', 'looved', 'the', 'battle', '', 'crakkbitch']\n",
      "<user> <user> thanks sir > > don't trip lil mama ... just keep doin ya thang !\n",
      "\n",
      "['user', 'user', 'thanks', 'sir', '', '', 'dont', 'trip', 'lil', 'mama', '', 'just', 'keep', 'doin', 'ya', 'thang', '']\n",
      "visiting my brother tmr is the bestest birthday gift eveerrr ! ! !\n",
      "\n",
      "['visiting', 'my', 'brother', 'tmr', 'is', 'the', 'bestest', 'birthday', 'gift', 'eveerrr', '', '', '']\n",
      "<user> yay ! ! #lifecompleted . tweet / facebook me to let me know please\n",
      "\n",
      "['user', 'yay', '', '', 'lifecompleted', '', 'tweet', '', 'facebook', 'me', 'to', 'let', 'me', 'know', 'please']\n",
      "<user> #1dnextalbumtitle : feel for you / rollercoaster of life . song cocept : life , #yolo , becoming famous ? <3 14 #followmeplz ! <3 x15\n",
      "\n",
      "['user', '1dnextalbumtitle', '', 'feel', 'for', 'you', '', 'rollercoaster', 'of', 'life', '', 'song', 'cocept', '', 'life', '', 'yolo', '', 'becoming', 'famous', '', '3', '14', 'followmeplz', '', '3', 'x15']\n",
      "workin hard or hardly workin rt <user> at hardee's with my future coworker <user>\n",
      "\n",
      "['workin', 'hard', 'or', 'hardly', 'workin', 'rt', 'user', 'at', 'hardees', 'with', 'my', 'future', 'coworker', 'user']\n",
      "<user> i saw . i'll be replying in a bit .\n",
      "\n",
      "['user', 'i', 'saw', '', 'ill', 'be', 'replying', 'in', 'a', 'bit', '']\n",
      "this is were i belong\n",
      "\n",
      "['this', 'is', 'were', 'i', 'belong']\n"
     ]
    }
   ],
   "source": [
    "for _tweet in tweets[1:10]:\n",
    "    print(_tweet)\n",
    "    # remove punctuation\n",
    "    words = _tweet.split()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    words = [w.translate(table) for w in words]\n",
    "    # normalize case\n",
    "    words = [word.lower() for word in words]\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "because your logic is so dumb , i won't even crop out your name or your photo . tsk . <url>\n",
      "\n",
      "['logic', 'dumb', 'wo', 'even', 'crop', 'name', 'photo', 'tsk', 'url']\n",
      "-----------------\n",
      "\" <user> just put casper in a box ! \" looved the battle ! #crakkbitch\n",
      "\n",
      "['user', 'put', 'casper', 'box', 'looved', 'battle', 'crakkbitch']\n",
      "-----------------\n",
      "<user> <user> thanks sir > > don't trip lil mama ... just keep doin ya thang !\n",
      "\n",
      "['user', 'user', 'thanks', 'sir', 'trip', 'lil', 'mama', 'keep', 'doin', 'ya', 'thang']\n",
      "-----------------\n",
      "visiting my brother tmr is the bestest birthday gift eveerrr ! ! !\n",
      "\n",
      "['visiting', 'brother', 'tmr', 'bestest', 'birthday', 'gift', 'eveerrr']\n",
      "-----------------\n",
      "<user> yay ! ! #lifecompleted . tweet / facebook me to let me know please\n",
      "\n",
      "['user', 'yay', 'lifecompleted', 'tweet', 'facebook', 'let', 'know', 'please']\n",
      "-----------------\n",
      "<user> #1dnextalbumtitle : feel for you / rollercoaster of life . song cocept : life , #yolo , becoming famous ? <3 14 #followmeplz ! <3 x15\n",
      "\n",
      "['user', 'feel', 'rollercoaster', 'life', 'song', 'cocept', 'life', 'yolo', 'becoming', 'famous', 'followmeplz']\n",
      "-----------------\n",
      "workin hard or hardly workin rt <user> at hardee's with my future coworker <user>\n",
      "\n",
      "['workin', 'hard', 'hardly', 'workin', 'rt', 'user', 'hardee', 'future', 'coworker', 'user']\n",
      "-----------------\n",
      "<user> i saw . i'll be replying in a bit .\n",
      "\n",
      "['user', 'saw', 'replying', 'bit']\n",
      "-----------------\n",
      "this is were i belong\n",
      "\n",
      "['belong']\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for _tweet in tweets[1:10]:\n",
    "    print(_tweet)\n",
    "    # split into words\n",
    "    tokens = word_tokenize(_tweet)\n",
    "    # filter stand-alone punctuation out\n",
    "    words = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    print(words)\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEMMING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= process of reducing inflected (or derived) words to their word stem, base or root form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "because your logic is so dumb , i won't even crop out your name or your photo . tsk . <url>\n",
      "\n",
      "['logic', 'dumb', 'wo', 'even', 'crop', 'name', 'photo', 'tsk', 'url']\n",
      "------------------------------------------------------------------\n",
      "\" <user> just put casper in a box ! \" looved the battle ! #crakkbitch\n",
      "\n",
      "['put', 'casper', 'box', 'looved', 'battle', 'crakkbitch']\n",
      "------------------------------------------------------------------\n",
      "<user> <user> thanks sir > > don't trip lil mama ... just keep doin ya thang !\n",
      "\n",
      "['thanks', 'sir', 'trip', 'lil', 'mama', 'keep', 'doin', 'ya', 'thang']\n",
      "------------------------------------------------------------------\n",
      "visiting my brother tmr is the bestest birthday gift eveerrr ! ! !\n",
      "\n",
      "['visiting', 'brother', 'tmr', 'bestest', 'birthday', 'gift', 'eveerrr']\n",
      "------------------------------------------------------------------\n",
      "<user> yay ! ! #lifecompleted . tweet / facebook me to let me know please\n",
      "\n",
      "['yay', 'lifecompleted', 'tweet', 'facebook', 'let', 'know', 'please']\n",
      "------------------------------------------------------------------\n",
      "<user> #1dnextalbumtitle : feel for you / rollercoaster of life . song cocept : life , #yolo , becoming famous ? <3 14 #followmeplz ! <3 x15\n",
      "\n",
      "['feel', 'rollercoaster', 'life', 'song', 'cocept', 'life', 'yolo', 'becoming', 'famous', 'followmeplz']\n",
      "------------------------------------------------------------------\n",
      "workin hard or hardly workin rt <user> at hardee's with my future coworker <user>\n",
      "\n",
      "['workin', 'hard', 'hardly', 'workin', 'rt', 'hardee', 'future', 'coworker']\n",
      "------------------------------------------------------------------\n",
      "<user> i saw . i'll be replying in a bit .\n",
      "\n",
      "['saw', 'replying', 'bit']\n",
      "------------------------------------------------------------------\n",
      "this is were i belong\n",
      "\n",
      "['belong']\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for _tweet in tweets[1:10]:\n",
    "    print(_tweet)\n",
    "    # split into words\n",
    "    tokens = word_tokenize(_tweet)\n",
    "    # filter out <user>\n",
    "    words = [w for w in tokens if not w in \"<user>\"]\n",
    "    # filter stand-alone punctuation out\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    print(words)\n",
    "    for _word in words:\n",
    "        ps.stem(_word)\n",
    "    print(\"------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sno = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "because your logic is so dumb , i won't even crop out your name or your photo . tsk . <url>\n",
      "\n",
      "['logic', 'dumb', 'wo', 'even', 'crop', 'name', 'photo', 'tsk', 'url']\n",
      "------------------------------------------------------------------\n",
      "\" <user> just put casper in a box ! \" looved the battle ! #crakkbitch\n",
      "\n",
      "['put', 'casper', 'box', 'looved', 'battle', 'crakkbitch']\n",
      "------------------------------------------------------------------\n",
      "<user> <user> thanks sir > > don't trip lil mama ... just keep doin ya thang !\n",
      "\n",
      "['thanks', 'sir', 'trip', 'lil', 'mama', 'keep', 'doin', 'ya', 'thang']\n",
      "------------------------------------------------------------------\n",
      "visiting my brother tmr is the bestest birthday gift eveerrr ! ! !\n",
      "\n",
      "['visiting', 'brother', 'tmr', 'bestest', 'birthday', 'gift', 'eveerrr']\n",
      "------------------------------------------------------------------\n",
      "<user> yay ! ! #lifecompleted . tweet / facebook me to let me know please\n",
      "\n",
      "['yay', 'lifecompleted', 'tweet', 'facebook', 'let', 'know', 'please']\n",
      "------------------------------------------------------------------\n",
      "<user> #1dnextalbumtitle : feel for you / rollercoaster of life . song cocept : life , #yolo , becoming famous ? <3 14 #followmeplz ! <3 x15\n",
      "\n",
      "['feel', 'rollercoaster', 'life', 'song', 'cocept', 'life', 'yolo', 'becoming', 'famous', 'followmeplz']\n",
      "------------------------------------------------------------------\n",
      "workin hard or hardly workin rt <user> at hardee's with my future coworker <user>\n",
      "\n",
      "['workin', 'hard', 'hardly', 'workin', 'rt', 'hardee', 'future', 'coworker']\n",
      "------------------------------------------------------------------\n",
      "<user> i saw . i'll be replying in a bit .\n",
      "\n",
      "['saw', 'replying', 'bit']\n",
      "------------------------------------------------------------------\n",
      "this is were i belong\n",
      "\n",
      "['belong']\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for _tweet in tweets[1:10]:\n",
    "    print(_tweet)\n",
    "    # split into words\n",
    "    tokens = word_tokenize(_tweet)\n",
    "    # filter out <user>\n",
    "    words = [w for w in tokens if not w in \"<user>\"]\n",
    "    # filter stand-alone punctuation out\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    print(words)\n",
    "    for _word in words:\n",
    "        sno.stem(_word)\n",
    "    print(\"------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEMMATIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=  process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word’s lemma, or dictionary form. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = nltk.wordnet.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "because your logic is so dumb , i won't even crop out your name or your photo . tsk . <url>\n",
      "\n",
      "['logic', 'dumb', 'wo', 'even', 'crop', 'name', 'photo', 'tsk', 'url']\n",
      "------------------------------------------------------------------\n",
      "\" <user> just put casper in a box ! \" looved the battle ! #crakkbitch\n",
      "\n",
      "['put', 'casper', 'box', 'looved', 'battle', 'crakkbitch']\n",
      "------------------------------------------------------------------\n",
      "<user> <user> thanks sir > > don't trip lil mama ... just keep doin ya thang !\n",
      "\n",
      "['thanks', 'sir', 'trip', 'lil', 'mama', 'keep', 'doin', 'ya', 'thang']\n",
      "------------------------------------------------------------------\n",
      "visiting my brother tmr is the bestest birthday gift eveerrr ! ! !\n",
      "\n",
      "['visiting', 'brother', 'tmr', 'bestest', 'birthday', 'gift', 'eveerrr']\n",
      "------------------------------------------------------------------\n",
      "<user> yay ! ! #lifecompleted . tweet / facebook me to let me know please\n",
      "\n",
      "['yay', 'lifecompleted', 'tweet', 'facebook', 'let', 'know', 'please']\n",
      "------------------------------------------------------------------\n",
      "<user> #1dnextalbumtitle : feel for you / rollercoaster of life . song cocept : life , #yolo , becoming famous ? <3 14 #followmeplz ! <3 x15\n",
      "\n",
      "['feel', 'rollercoaster', 'life', 'song', 'cocept', 'life', 'yolo', 'becoming', 'famous', 'followmeplz']\n",
      "------------------------------------------------------------------\n",
      "workin hard or hardly workin rt <user> at hardee's with my future coworker <user>\n",
      "\n",
      "['workin', 'hard', 'hardly', 'workin', 'rt', 'hardee', 'future', 'coworker']\n",
      "------------------------------------------------------------------\n",
      "<user> i saw . i'll be replying in a bit .\n",
      "\n",
      "['saw', 'replying', 'bit']\n",
      "------------------------------------------------------------------\n",
      "this is were i belong\n",
      "\n",
      "['belong']\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for _tweet in tweets[1:10]:\n",
    "    print(_tweet)\n",
    "    # split into words\n",
    "    tokens = word_tokenize(_tweet)\n",
    "        # filter out <user>\n",
    "    words = [w for w in tokens if not w in \"<user>\"]\n",
    "    # filter stand-alone punctuation out\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    print(words)\n",
    "    for _word in words:\n",
    "        lemma.lemmatize(_word)\n",
    "    print(\"------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpaCy Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "because your logic is so dumb , i won't even crop out your name or your photo . tsk . <url>\n",
      "\n",
      "['because', '-PRON-', 'logic', 'be', 'so', 'dumb', ',', 'i', 'will', 'not', 'even', 'crop', 'out', '-PRON-', 'name', 'or', '-PRON-', 'photo', '.', 'tsk', '.', '<', 'url', '>', '\\n']\n",
      "------------------------------------------------------------------\n",
      "\" <user> just put casper in a box ! \" looved the battle ! #crakkbitch\n",
      "\n",
      "['\"', '<', 'user', '>', 'just', 'put', 'casper', 'in', 'a', 'box', '!', '\"', 'loove', 'the', 'battle', '!', '#', 'crakkbitch', '\\n']\n",
      "------------------------------------------------------------------\n",
      "<user> <user> thanks sir > > don't trip lil mama ... just keep doin ya thang !\n",
      "\n",
      "['<', 'user', '>', '<', 'user', '>', 'thank', 'sir', '>', '>', 'do', 'not', 'trip', 'lil', 'mama', '...', 'just', 'keep', 'do', 'ya', 'thang', '!', '\\n']\n",
      "------------------------------------------------------------------\n",
      "visiting my brother tmr is the bestest birthday gift eveerrr ! ! !\n",
      "\n",
      "['visit', '-PRON-', 'brother', 'tmr', 'be', 'the', 'best', 'birthday', 'gift', 'eveerrr', '!', '!', '!', '\\n']\n",
      "------------------------------------------------------------------\n",
      "<user> yay ! ! #lifecompleted . tweet / facebook me to let me know please\n",
      "\n",
      "['<', 'user', '>', 'yay', '!', '!', '#', 'lifecomplete', '.', 'tweet', '/', 'facebook', '-PRON-', 'to', 'let', '-PRON-', 'know', 'please', '\\n']\n",
      "------------------------------------------------------------------\n",
      "<user> #1dnextalbumtitle : feel for you / rollercoaster of life . song cocept : life , #yolo , becoming famous ? <3 14 #followmeplz ! <3 x15\n",
      "\n",
      "['<', 'user', '>', '#', '1dnextalbumtitle', ':', 'feel', 'for', '-PRON-', '/', 'rollercoaster', 'of', 'life', '.', 'song', 'cocept', ':', 'life', ',', '#', 'yolo', ',', 'become', 'famous', '?', '<3', '14', '#', 'followmeplz', '!', '<3', 'x15', '\\n']\n",
      "------------------------------------------------------------------\n",
      "workin hard or hardly workin rt <user> at hardee's with my future coworker <user>\n",
      "\n",
      "['workin', 'hard', 'or', 'hardly', 'workin', 'rt', '<', 'user', '>', 'at', 'hardee', \"'s\", 'with', '-PRON-', 'future', 'coworker', '<', 'user', '>', '\\n']\n",
      "------------------------------------------------------------------\n",
      "<user> i saw . i'll be replying in a bit .\n",
      "\n",
      "['<', 'user', '>', 'i', 'see', '.', '-PRON-', 'will', 'be', 'reply', 'in', 'a', 'bit', '.', '\\n']\n",
      "------------------------------------------------------------------\n",
      "this is were i belong\n",
      "\n",
      "['this', 'be', 'be', 'i', 'belong', '\\n']\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for _tweet in tweets[1:10]:\n",
    "    print(_tweet)\n",
    "    words = sp(_tweet)\n",
    "    lemmas = []\n",
    "    for word in words:\n",
    "        lemmas.append(word.lemma_)\n",
    "    print(lemmas)\n",
    "    print(\"------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
